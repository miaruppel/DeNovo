{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75257c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyopenms import * # main package used for handling MS data\n",
    "import os # changing directories\n",
    "import pandas as pd # creating and manipulating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ae3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to find data files of interest\n",
    "os.chdir(r'C:\\Users\\miar\\Desktop\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bd296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment files \n",
    "mzML = 'HEK293T_De_Novo_061122_Glu-C_B_BP_anyLength_HCD10.mzML'\n",
    "log = 'App-2022-06-12_14-16-26.log'\n",
    "realtime = 'HEK293T_De_Novo_061122_Glu-C_B_BP_anyLength_HCD10_realtimesearch.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec58c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the content of the mzML file into the exp variable of type MSExperiment\n",
    "exp = MSExperiment()\n",
    "MzMLFile().load(mzML, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85506994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the spectra to filter MS3 scans\n",
    "specM3 = [] # list of MS3 spectra \n",
    "row_data = []\n",
    "for s in exp.getSpectra():\n",
    "    \n",
    "    if s.getMSLevel() == 3:\n",
    "        specM3.append(s)\n",
    "        \n",
    "        # get scan number\n",
    "        s_number = s.getNativeID().split(' ')[-1]\n",
    "        _, scan_number = s_number.split('=')\n",
    "        \n",
    "        # obtain mz and intensity values \n",
    "        mz, intensity = s.get_peaks()\n",
    "        \n",
    "        mz_mod = \" \".join(str(m) for m in mz)\n",
    "        intensity_mod = \" \".join(str(i) for i in intensity)\n",
    "        \n",
    "        # create dict (rows of dataframe)\n",
    "        data = {#'MS3_Scan':scan_number,\n",
    "       'masses_raw':mz_mod,\n",
    "       'intensities_raw':intensity_mod}\n",
    "        \n",
    "        row_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d968bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series of all MS3 spectra\n",
    "s_series = pd.Series(specM3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6e1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set MS3 scans as index\n",
    "df = pd.DataFrame(row_data)\n",
    "#df.set_index('MS3_Scan', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d94390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse functions\n",
    "def parseScanLine(input):\n",
    "    x = input.split(\" For: \")\n",
    "    [scan_number, mzs] = x[1].split(\", \")\n",
    "    [precursor_mz, fragment_mz] = mzs.split(\";\")\n",
    "    trimmed_fragment_mz = fragment_mz.strip() # trim fragment strings to remove \\n\n",
    "    return [scan_number, precursor_mz, trimmed_fragment_mz]\n",
    "\n",
    "def parseTargetIons(input):\n",
    "    i = input.split('Target Fragment: ')\n",
    "    ion = i[1].split(',')[0]\n",
    "    return ion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409aaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking lines of log file and creating dictionary of scan numbers and fragment mzs\n",
    "try:\n",
    "  \n",
    "    # words to search for\n",
    "    search = ' Submitted Custom Scan For:'\n",
    "    \n",
    "    # dict for scan numbers and corresponding fragments \n",
    "    scan2frag = dict()\n",
    "    with open(log) as f:\n",
    "        for line in f:\n",
    "            if search in line:\n",
    "                scan_number, precursor_mz, trimmed_fragment_mz = parseScanLine(line)\n",
    "                scan2frag[scan_number] = [float(precursor_mz), float(trimmed_fragment_mz)]\n",
    "            \n",
    "    # if the input string doesn't exist in the text file\n",
    "    if len(scan2frag)==0:\n",
    "        print(\"\\n\\\"\" + search + \"\\\" is not found in \\\"\" + log + \"\\\"!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"The file does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d3272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain MS3 scan numbers\n",
    "# obtain precursor and fragment mzs directly from the MS3 spectrum\n",
    "\n",
    "ms3scan2MZs = dict()\n",
    "for s in specM3:\n",
    "    s_number = s.getNativeID().split(' ')[-1]\n",
    "    _, scan_number = s_number.split('=')\n",
    "   \n",
    "    fragment, precursor = s.getPrecursors()\n",
    "    precursor_mz = precursor.getMZ()\n",
    "    fragment_mz = fragment.getMZ()\n",
    "    \n",
    "    ms3scan2MZs[int(scan_number)] = [round(float(precursor_mz), 4), round(float(fragment_mz), 4)] # 4 decimal places, similar to log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8932c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchingMS3s(ms2_mzs, ms3_mzs): # either fragment or precursor\n",
    "    \n",
    "    # making sure they are within 100 scans of each other\n",
    "    too_far = []\n",
    "    for ms2scan, ms3scan in zip(list(scan2frag), list(ms3scan2MZs)):\n",
    "        scan_diff = int(ms3scan) - int(ms2scan)\n",
    "        if scan_diff > 100:\n",
    "            too_far.append('Scans are not within 100 scans of each other...' + 'MS2 = ' + str(ms2scan) + ' MS3 = ' + str(ms3scan))\n",
    "    \n",
    "    # do they not match off the bat?\n",
    "    if ms2_mzs != ms3_mzs:\n",
    "        # taking into consideration rounding discrepencies between the log and the spectrum\n",
    "        mismatch = []\n",
    "        for i in range(0, len(list(ms3scan2MZs))):\n",
    "            \n",
    "            precursor_diff = float(list(ms3scan2MZs.values())[i][0]) - float(list(scan2frag.values())[i][0]) \n",
    "            if precursor_diff < 0.000101 or (precursor_diff < 0 and precursor_diff > -0.000101): # because sometimes max number will be 0.0001000002 for example\n",
    "                pass\n",
    "            else:\n",
    "                mismatch.append(i)\n",
    "            \n",
    "            fragment_diff = float(list(ms3scan2MZs.values())[i][1]) - float(list(scan2frag.values())[i][1]) \n",
    "            if fragment_diff < 0.000101 or (fragment_diff < 0 and fragment_diff > -0.000101): # because sometimes max number will be 0.0001000002 for example\n",
    "                pass\n",
    "            else:\n",
    "                mismatch.append(i)\n",
    "                \n",
    "        # no mismatch after rounding and within 100 scans\n",
    "        if len(mismatch) == len(too_far) == 0:\n",
    "            print('Scans match up after taking rounding discrepencies into consideration')\n",
    "            ms2_scans = list(scan2frag)\n",
    "            return ms2_scans\n",
    "        \n",
    "        elif len(mismatch) != 0:\n",
    "            print('There is mismatch at the following indicies:') # if this is the case, need to do more work...\n",
    "            for i in mismatch:\n",
    "                print(i) \n",
    "                \n",
    "        elif len(too_far) != 0:\n",
    "            print(too_far)\n",
    "        \n",
    "    # they match perfectly\n",
    "    elif ms2_mzs == ms3_mzs:\n",
    "        # within 100 scans\n",
    "        if len(too_far) == 0:\n",
    "            print('Scans match up perfectly!')\n",
    "            ms2_scans = list(scan2frag)\n",
    "            return ms2_scans\n",
    "        else:\n",
    "            print(too_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230d2e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans match up after taking rounding discrepencies into consideration\n"
     ]
    }
   ],
   "source": [
    "# make sure that MS3 scans are in the same order as MS2 scans\n",
    "ms2_scans = matchingMS3s(list(ms3scan2MZs.values()), list(scan2frag.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d0074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use realtime file to obtain peptide sequence and charge\n",
    "# read in peptide sequence from tsv\n",
    "tsv = pd.read_csv(realtime, sep='\\t')\n",
    "\n",
    "# create dictionary with scan # as key and sequence/charge as values\n",
    "scan2PeptideCharge = dict([(i, [x,y]) for i, x,y, in zip(tsv['Scan Number'], tsv['Peptide'], tsv['Charge State'])])\n",
    "\n",
    "# removing all NaN sequences (not useful)\n",
    "scan2PeptideCharge_modified = {k:v for k,v in scan2PeptideCharge.items() if str(v[0]) != 'nan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8ed0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data for dataframe\n",
    "seqs = []\n",
    "charges = []\n",
    "analyzer = []\n",
    "collision = []\n",
    "\n",
    "energy = int(realtime.split('_')[-2][-2:])\n",
    "\n",
    "for scan in ms2_scans:\n",
    "    if int(scan) in list(scan2PeptideCharge_modified):\n",
    "        charge = scan2PeptideCharge_modified[int(scan)][1]\n",
    "        charges.append(charge)\n",
    "        \n",
    "        sequence = scan2PeptideCharge_modified[int(scan)][0]     \n",
    "        trimmed_sequence = sequence[2:-2] # remove first two and last two characters \n",
    "        seqs.append(trimmed_sequence)\n",
    "        \n",
    "        # all ms3 scans are orbit trap \n",
    "        # to be added to dataframe with other MS3 info\n",
    "        analyzer.append('FTMS')\n",
    "        \n",
    "        # all scans have same collision energy\n",
    "        collision.append(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "022c4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all data columns to dataframe\n",
    "df = df.assign(charge=charges, modified_sequence=seqs, mass_analyzer=analyzer, collision_energy=collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d58968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all modified sequences\n",
    "for i in df.index:\n",
    "    if ('[' or ']') in df['modified_sequence'][i]:\n",
    "        df.drop(i, axis=0, inplace=True)\n",
    "        s_series.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a15d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all sequences more than 30 in length\n",
    "for i in df.index:\n",
    "    if len(df['modified_sequence'][i]) >= 30:\n",
    "        df.drop(i, axis=0, inplace=True)\n",
    "        s_series.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7960147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing variables and functions from other scripts\n",
    "from constants import ION_TYPES, DEFAULT_MAX_CHARGE\n",
    "from match import augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c4c7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running augment function\n",
    "df_augmented = augment(df, ION_TYPES, DEFAULT_MAX_CHARGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e8e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that are completely empty\n",
    "for i in df_augmented.index:\n",
    "    if df_augmented['matches_charge1'][i] == df_augmented['matches_charge2'][i] == df_augmented['matches_charge3'][i] == df_augmented['matches_charge4'][i] == df_augmented['matches_charge5'][i] == df_augmented['matches_charge6'][i]:\n",
    "        df_augmented.drop(i, axis=0, inplace=True)\n",
    "        s_series.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61d799d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run csv function 'charge' needs to be replaced with 'precursor_charge' ?\n",
    "df_augmented.rename(columns = {'charge':'precursor_charge'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "54d36b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import another important function from tensorize script\n",
    "import tensorize as tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6c512d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorize' from 'C:\\\\Users\\\\miar\\\\Documents\\\\GitHub\\\\DeNovo\\\\tensorize.py'>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reloading with troubleshooting\n",
    "import importlib\n",
    "importlib.reload(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "37ffbafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.06043417  74.53385532  -1.         ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [148.06043417  74.53385532  50.0249957  ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [148.06043417  74.53385532  -1.         ...  -1.          -1.\n",
      "   -1.        ]\n",
      " ...\n",
      " [134.04478417  67.52603032  45.35311237 ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [134.04478417  67.52603032  45.35311237 ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [148.06043417  74.53385532  -1.         ...  -1.          -1.\n",
      "   -1.        ]]\n",
      "[[-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "# create dictionary of data\n",
    "data = tens.csv_training(df_augmented, s_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7c4ac8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collision_energy_aligned_normed': array([[0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1],\n",
       "        [0.1]]),\n",
       " 'sequence_integer': array([[12, 16, 17, ...,  0,  0,  0],\n",
       "        [14,  1, 13, ...,  0,  0,  0],\n",
       "        [ 8, 13, 10, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 9,  9, 20, ...,  0,  0,  0],\n",
       "        [ 6, 14,  1, ...,  0,  0,  0],\n",
       "        [ 8,  1, 14, ...,  0,  0,  0]]),\n",
       " 'precursor_charge_onehot': array([[0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]]),\n",
       " 'masses_pred': array([[-1., -1., -1., ..., -1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [-1., -1., -1., ..., -1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1., -1.]]),\n",
       " 'intensities_raw': array([[-5.19194841e-04, -5.19194841e-04, -5.19194841e-04, ...,\n",
       "         -5.19194841e-04, -5.19194841e-04, -5.19194841e-04],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "        [-4.30041828e-04, -4.30041828e-04, -4.30041828e-04, ...,\n",
       "         -4.30041828e-04, -4.30041828e-04, -4.30041828e-04],\n",
       "        ...,\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
       "        [-3.94748378e-04, -3.94748378e-04, -3.94748378e-04, ...,\n",
       "         -3.94748378e-04, -3.94748378e-04, -3.94748378e-04]])}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d905db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code does not work properly \n",
    "# GPU configuration issues\n",
    "# moved to computer cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4820e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import another important function from io_local script\n",
    "#from io_local import to_hdf5, from_hdf5\n",
    "\n",
    "# convert dictionary data to hdf5 \n",
    "#to_hdf5(data, 'hdf5_data2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c70322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in ML packages and created data matrix\n",
    "#import tensorflow\n",
    "#from tensorflow import keras\n",
    "#from keras.utils import HDF5Matrix\n",
    "\n",
    "# load in hdf5 snd create matrix\n",
    "#tensor = from_hdf5('hdf5_data.hdf5', n_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model \n",
    "#import training\n",
    "#import model as model_lib\n",
    "# load in model\n",
    "#model, model_config = model_lib.load(r\"C:\\Users\\miar\\Downloads\\model_fragmentation_prediction\\prosit1\", trained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf551a-c01e-4d60-8474-f14ff9d615c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(model_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01b89f-68c4-4e51-a3e5-f6ef2e892437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311a9e2-842c-43ce-afdf-76e06fad5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c72271-0ac7-4ba9-bc06-d496f5bc5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf \n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c90ab0-7a34-401c-b6d7-d1ad6d0ae5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#def get_available_devices():\n",
    "#    local_device_protos = device_lib.list_local_devices()\n",
    "#    return [x.name for x in local_device_protos]\n",
    "#print(get_available_devices()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
